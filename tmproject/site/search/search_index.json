{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documentaci\u00f3 del Codi","text":"<p>Benvinguts a la documentaci\u00f3 del codi del c\u00f2dec de v\u00eddeo per al Projecte de Pr\u00e0ctiques de Tecnologies Multim\u00e8dia. Aquest codi implementa les diferents funcionalitats demanades.</p>"},{"location":"#contingut","title":"Contingut","text":"<p>Aquest projecte es divideix en diferents parts, cadascun d'ells compleix una funcionalitat diferent i junts composen el c\u00f2dec de v\u00eddeo.</p> <ul> <li> <p>cli.py: Aquest fitxer cont\u00e9 la implementaci\u00f3 de la interf\u00edcie de l\u00ednia de comandes (CLI) per al projecte. Defineix els comandaments i opcions que els usuaris poden utilitzar per interactuar amb el programa des de la l\u00ednia de comandes. A m\u00e9s, en el nostre projecte funciona com una clase Controller, i actua com a intermediari entre les diferents funcionalitats del c\u00f2dec.</p> </li> <li> <p>create_output.py: Aquest fitxer cont\u00e9 funcions per crear la sortida del projecte, creant un fitxer zip amb les diferents imatges en format JPEG. Aquestes imatges poden estar modificades o no gracies a altres m\u00f2duls. En cas que es comprimeixi les imatges, s'afegira un arxiu JSON amb la informaci\u00f3 per descodificar-les.</p> </li> <li> <p>decoder.py: En aquest fitxer es troba la implementaci\u00f3 del descodificador, que pren imatges codificades i les converteix de nou en el seu format original.</p> </li> <li> <p>encoder.py: Aquest fitxer cont\u00e9  la implementaci\u00f3 del codificador. Aquest codificador fa la compressi\u00f3 d'un v\u00eddeo sense audio. Per fer la compressi\u00f3 s'ha fet servir un algoritme de correspondencia de tesela.</p> </li> <li> <p>filters.py: Aqu\u00ed es troben les implementacions dels diferents filtres que es poden aplicar al v\u00eddeo processats pel projecte. Aquests filtres poden incloure funcions per ajustar la brillantor, el contrast, aplicar efectes de color, etc.</p> </li> <li> <p>read_input.py: Aquest fitxer cont\u00e9 funcions per llegir les dades d'entrada del projecte, com arxius d'imatge, zips o v\u00eddeo.</p> </li> <li> <p>reproduce_video.py: Aqu\u00ed es troba la l\u00f2gica per reproduir v\u00eddeos processats pel projecte.</p> </li> </ul> <p>Hi ha altres parts del projecte que no tenen gaire rellev\u00e0ncia i s'expliquen breument a continuaci\u00f3:</p> <ul> <li> <p><code>__init__.py</code>: Aquest fitxer indica que el directori <code>tmproject</code> \u00e9s un paquet de Python, permetent la importaci\u00f3 de m\u00f2duls dins d'ell.</p> </li> <li> <p><code>__main__.py</code>: Aquest fitxer cont\u00e9 el punt d'entrada principal del paquet. S'executa quan es crida al paquet com a script (<code>python -m tmproject</code> o <code>tmproject</code> en cas que tinguis el paquet local). Aquest arxiu serveix \u00fanicament per cridar la funci\u00f3 main de <code>cli.py</code>.</p> </li> </ul>"},{"location":"cli/","title":"Documentaci\u00f3 de cli.py","text":""},{"location":"cli/#introduccio","title":"Introducci\u00f3","text":"<p>El fitxer <code>cli.py</code> \u00e9s un component essencial del projecte del c\u00f2dec de v\u00eddeo, on s'implementa la interf\u00edcie de l\u00ednia de comandes (CLI) utilitzant la biblioteca Click. Aquest m\u00f2dul facilita la interacci\u00f3 amb l'usuari, permetent-li executar diverses operacions en fitxers d'imatge i v\u00eddeo mitjan\u00e7ant comandaments espec\u00edfics.</p>"},{"location":"cli/#us-de-click","title":"\u00das de Click","text":"<p>Click \u00e9s una biblioteca de Python per a la creaci\u00f3 d'interf\u00edcies de l\u00ednia de comandes. Permet definir comandaments, opcions i arguments de forma f\u00e0cil i flexible. <code>cli.py</code> utilitza Click per proporcionar una CLI intu\u00eftiva i f\u00e0cil d'utilitzar per al projecte del c\u00f2dec de v\u00eddeo.</p>"},{"location":"cli/#exemples-dus","title":"Exemples d'\u00das","text":"<ul> <li>Codificar un v\u00eddeo i desar el resultat en un fitxer ZIP:</li> </ul> <p><code>tmproject -i video.avi -o video_comprimit.zip --fps 30 --filter \"sepia;brillo=-50,1.5\" --quality 0.8</code></p> <ul> <li>Mostrar informaci\u00f3 sobre els filtres disponibles:</li> </ul> <p><code>tmproject -i video.avi --filter-help</code></p> <ul> <li>Reproduir un v\u00eddeo amb una taxa de fotogrames de 60 FPS:</li> </ul> <p><code>tmproject -i video.avi --fps 60</code></p> <ul> <li>Descodificar un video, aplicar filtres i reproduir-lo:</li> </ul> <p><code>tmproject -i video_comprimit.zip --filter \"averaging;grey;edges;embossing;sharp;sepia;negative;blur=5;brillo=-50,1\"</code></p> <p>Aquest s\u00f3n exemples de com utilitzar la CLI proporcionada per <code>cli.py</code>. Pots ajustar els arguments segons les teves necessitats espec\u00edfiques.</p>"},{"location":"cli/#funcions","title":"Funcions","text":""},{"location":"cli/#cli.encode_info","title":"<code>encode_info(input, output, total_time, original_images, images)</code>","text":"<p>Calcula i mostra informaci\u00f3 sobre la compressi\u00f3 despr\u00e9s de l'operaci\u00f3 de codificaci\u00f3.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>Ruta al fitxer d'entrada.</p> required <code>output</code> <code>str</code> <p>Ruta al fitxer de sortida.</p> required <code>total_time</code> <code>float</code> <p>Temps total de processament en segons.</p> required Source code in <code>cli.py</code> <pre><code>def encode_info(input, output, total_time, original_images, images):\n    \"\"\"\n    Calcula i mostra informaci\u00f3 sobre la compressi\u00f3 despr\u00e9s de l'operaci\u00f3 de codificaci\u00f3.\n\n    Args:\n        input (str): Ruta al fitxer d'entrada.\n        output (str): Ruta al fitxer de sortida.\n        total_time (float): Temps total de processament en segons.\n    \"\"\"\n    original_zip_size = os.path.getsize(input)\n    compressed_zip_size = os.path.getsize(output)\n    compression_ratio = original_zip_size / compressed_zip_size\n    improvement = (original_zip_size - compressed_zip_size) / original_zip_size * 100\n    click.echo(\"Informe sobre la compressi\u00f3:\")\n    if total_time &gt; 60:\n        minutes = total_time // 60\n        seconds = total_time % 60\n        click.echo(f\"Temps total de processament: {int(minutes)} minuts {str(round(seconds))} segons.\")\n    else:\n        click.echo(f\"Temps total de processament: {str(round(total_time,2))} segons.\")\n    click.echo(f\"Ratio de compressi\u00f3: {str(round(compression_ratio,2))}.\")\n    click.echo(f\"Millora en l'espai ocupat per l'arxiu ZIP final: {str(round(improvement,2))}%\")\n    psnr = encoder.calculate_psnr(original_images, images)\n    if psnr is not None:\n        click.echo(f\"PSNR del v\u00eddeo comprimit: {str(round(psnr,2))} dB.\")\n    else:\n        click.echo(\"No s'ha pogut calcular el PSNR ja que les imatges s\u00f3n iguals.\")\n</code></pre>"},{"location":"cli/#cli.main","title":"<code>main(input, output, fps, filter, filter_help, ntiles, seekrange, gop, quality, reproduce)</code>","text":"<p>Processa un fitxer de v\u00eddeo, aplicant codificaci\u00f3/descodificaci\u00f3 i filtres especificats, i genera un fitxer ZIP amb el resultat.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>Ruta al fitxer d'entrada. </p> required <code>output</code> <code>str</code> <p>Ruta al fitxer de sortida. </p> required <code>fps</code> <code>int</code> <p>Nombre d'imatges per segon per a la reproducci\u00f3 del v\u00eddeo.</p> required <code>filter</code> <code>str</code> <p>Filtres a aplicar amb la sintaxi \"filtre=valor\".</p> required <code>filter_help</code> <code>bool</code> <p>Indica si es mostra informaci\u00f3 sobre els filtres disponibles.</p> required <code>ntiles</code> <code>tuple</code> <p>Nombre de tessel\u00b7les en els eixos vertical i horitzontal.</p> required <code>seekrange</code> <code>int</code> <p>Despla\u00e7ament m\u00e0xim en la cerca de tessel\u00b7les coincidents.</p> required <code>gop</code> <code>int</code> <p>Nombre d'imatges entre dos frames de refer\u00e8ncia.</p> required <code>quality</code> <code>float</code> <p>Factor de qualitat per determinar quan dues tessel\u00b7les es consideren coincidents.</p> required <code>reproduce</code> <code>bool</code> <p>Indica si es reprodueix el v\u00eddeo de sortida. Encara que hi hagi un fitxer de sortida.</p> required Source code in <code>cli.py</code> <pre><code>@click.command()\n@click.option('-i', '--input', required=True, help='Fitxer d\u2019entrada.')\n@click.option('-o', '--output', help='Fitxer de sortida.')\n@click.option('--fps', type=int, default=25, help='Nombre d\u2019imatges per segon amb les quals \u00e9s reproduir\u00e0 el v\u00eddeo.')\n@click.option('--filter', help='Aplica filtres acumulatius amb sintaxi \"filtre=valor\".')\n@click.option('--filter-help', is_flag=True, help='Mostra informaci\u00f3 sobre els filtres disponibles.')\n@click.option('--nTiles', type=(int, int), default=(4, 4), help='Nombre de tessel\u00b7les en els eixos vertical i horitzontal en les quals dividir la imatge.')\n@click.option('--seekRange', type=int, default=0, help='Despla\u00e7ament m\u00e0xim en la cerca de tessel\u00b7les coincidents.')\n@click.option('--GOP', type=int, default=10, help='Nombre d\u2019imatges entre dos frames de refer\u00e8ncia.')\n@click.option('--quality', type=float, default=0.9, help='Factor de qualitat que determinar\u00e0 quan dues tessel\u00b7les es consideren coincidents.')\n@click.option('--reproduce', is_flag=True, help='Reprodueix el v\u00eddeo de sortida. Encara que hi hagi un fitxer de sortida.')\n@click.help_option('--help', '-h')\ndef main(input, output, fps, filter, filter_help, ntiles, seekrange, gop, quality, reproduce):\n    \"\"\"\n    Processa un fitxer de v\u00eddeo, aplicant codificaci\u00f3/descodificaci\u00f3 i filtres especificats, i genera un fitxer ZIP amb el resultat.\n\n    Args:\n        input (str): Ruta al fitxer d'entrada. \n        output (str): Ruta al fitxer de sortida. \n        fps (int): Nombre d'imatges per segon per a la reproducci\u00f3 del v\u00eddeo.\n        filter (str): Filtres a aplicar amb la sintaxi \"filtre=valor\".\n        filter_help (bool): Indica si es mostra informaci\u00f3 sobre els filtres disponibles.\n        ntiles (tuple): Nombre de tessel\u00b7les en els eixos vertical i horitzontal.\n        seekrange (int): Despla\u00e7ament m\u00e0xim en la cerca de tessel\u00b7les coincidents.\n        gop (int): Nombre d'imatges entre dos frames de refer\u00e8ncia.\n        quality (float): Factor de qualitat per determinar quan dues tessel\u00b7les es consideren coincidents.\n        reproduce (bool): Indica si es reprodueix el v\u00eddeo de sortida. Encara que hi hagi un fitxer de sortida.\n    \"\"\"\n    if filter_help:\n        click.echo(FILTER_HELP)\n        return\n\n    images = {}  # Diccionari per emmagatzemar les imatges\n    metadata = {}  # Metadades de l'encoder\n    is_encoded = False\n    is_grayscale = False\n\n    metadata = {\n        \"encoder_parameters\": {\n            \"n_tiles_x\": ntiles[0],\n            \"n_tiles_y\": ntiles[1],\n            \"gop\": gop,\n            \"quality\": quality,\n            \"seek_range\": seekrange\n        },\n        \"frames\": [],\n        \"filters\": []\n    }\n\n    if input.endswith('.zip'):\n        click.echo('Obrint fitxer zip...')\n        is_encoded, is_grayscale = read_input.open_zip(input, images, metadata)\n    elif input.endswith('.gif'):\n        click.echo('Obrint fitxer GIF...')\n        is_grayscale = read_input.read_gif(input, images)\n    elif input.endswith(('.avi', '.mpeg', '.mp4')):\n        click.echo('Obrint fitxer de v\u00eddeo...')\n        is_grayscale = read_input.read_video(input, images)\n    else:\n        click.echo('Format d\u2019entrada no v\u00e0lid. Nom\u00e9s s\u2019accepten fitxers de v\u00eddeo (AVI, MPEG o MP4) o fitxers ZIP.')\n        return\n\n    if is_encoded:\n        start_time = time.time() \n        click.echo('Executant descodificaci\u00f3...')\n        decoder.main(images, metadata)\n        end_time = time.time()\n        total_time = end_time - start_time\n        click.echo(\"Temps total de descodificaci\u00f3: \"+ str(round(total_time,2)) + \" segons.\")\n\n    if filter:\n        filters_split = filter.split(';')\n        filters.main(filters_split, images, metadata, click, is_encoded, is_grayscale)\n\n    if output:\n        if not is_encoded:\n            start_time = time.time()\n            original_images = images.copy()  # for psnr calculation\n            click.echo(f'Executant codificaci\u00f3: nTiles[{ntiles}], seekRange[{seekrange}], GOP[{gop}], quality[{quality}]...')\n            encoder.main(images, ntiles, seekrange, gop, quality, metadata)\n            end_time = time.time()\n            total_time = end_time - start_time\n\n            click.echo('Guardant video en zip...')\n            create_output.create_zip(output, images, metadata, is_encoded)\n\n            encode_info(input, output, total_time, original_images, images)\n        else:\n            click.echo('Guardant video en zip...')\n            create_output.create_zip(output, images, metadata, is_encoded)\n\n        if reproduce:\n            reproduce_video.show_video(fps, images)\n    else:\n        reproduce_video.show_video(fps, images)\n</code></pre>"},{"location":"decoder/","title":"Documentaci\u00f3 de decoder.py","text":""},{"location":"decoder/#funcions","title":"Funcions","text":""},{"location":"decoder/#decoder.get_frame_by_file_name","title":"<code>get_frame_by_file_name(frames, file_name)</code>","text":"<p>Obt\u00e9 la informaci\u00f3 del fotograma corresponent al nom del fitxer donat.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>list</code> <p>Llista de diccionaris que contenen la informaci\u00f3 dels fotogrames.</p> required <code>file_name</code> <code>str</code> <p>Nom del fitxer per buscar el fotograma corresponent.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict or None</code> <p>Diccionari amb la informaci\u00f3 del fotograma corresponent al nom del fitxer donat.</p> Source code in <code>decoder.py</code> <pre><code>def get_frame_by_file_name(frames, file_name) -&gt; dict or None:\n    \"\"\"\n    Obt\u00e9 la informaci\u00f3 del fotograma corresponent al nom del fitxer donat.\n\n    Args:\n        frames (list): Llista de diccionaris que contenen la informaci\u00f3 dels fotogrames.\n        file_name (str): Nom del fitxer per buscar el fotograma corresponent.\n\n    Returns:\n        dict: Diccionari amb la informaci\u00f3 del fotograma corresponent al nom del fitxer donat.\n    \"\"\"\n    for frame in frames:\n        if frame[\"file_name\"] == file_name:\n            return frame\n    return None  # Si no se encuentra ning\u00fan marco con el nombre de archivo dado\n</code></pre>"},{"location":"decoder/#decoder.main","title":"<code>main(images, metadata)</code>","text":"<p>Descodifica els grups d'imatges a partir de la informaci\u00f3 de les metadades.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>dict</code> <p>Diccionari amb les imatges.</p> required <code>metadata</code> <code>dict</code> <p>Metadades del encoder que contenen els par\u00e0metres i la informaci\u00f3 dels frames.</p> required Source code in <code>decoder.py</code> <pre><code>def main(images, metadata):\n    \"\"\"\n    Descodifica els grups d'imatges a partir de la informaci\u00f3 de les metadades.\n\n    Args:\n        images (dict): Diccionari amb les imatges.\n        metadata (dict): Metadades del encoder que contenen els par\u00e0metres i la informaci\u00f3 dels frames.\n    \"\"\"\n    # Obtener los par\u00e1metros necesarios del metadata\n    gop_size = metadata[\"encoder_parameters\"][\"gop\"]\n    ntiles = (metadata[\"encoder_parameters\"][\"n_tiles_x\"], metadata[\"encoder_parameters\"][\"n_tiles_y\"])\n    frames = metadata[\"frames\"]\n\n    # Dividir las im\u00e1genes en grupos seg\u00fan el GOP\n    image_groups = encoder.split_images_into_groups(images, gop_size)\n\n    # Inicializar la barra de progreso para los grupos de im\u00e1genes\n    for image_group in tqdm(image_groups, desc=\"Descodificant grups d'imatges\"):\n        reference_image = None\n        for file_name, image in image_group.items():\n            # Obtener la informaci\u00f3n del frame actual\n            frame = get_frame_by_file_name(frames, file_name)\n            height, width = image.shape[:2]\n            tile_height = height // ntiles[1]\n            tile_width = width // ntiles[0]\n\n            if frame[\"reference_frame\"]:\n                reference_image = images[file_name]\n                ref_tiles = encoder.subdivide_image_into_tiles(reference_image, tile_height, tile_width, ntiles)\n            else:\n                for tile_info in frame[\"tiles\"]:\n                    # Obtener informaci\u00f3n de la tesela\n                    tb_id = tuple(tile_info[\"tb_id\"])\n                    td_position = tile_info[\"td_position\"]\n                    x, y = td_position\n\n                    # Calcular el tama\u00f1o de la tesela de referencia\n                    ref_tile_height = tile_height if y + tile_height &lt;= height else height - y\n                    ref_tile_width = tile_width if x + tile_width &lt;= width else width - x\n\n                    # Obtener la tesela de referencia\n                    reference_tile = ref_tiles[tb_id][:ref_tile_height, :ref_tile_width]\n                    images[file_name][y:y+ref_tile_height, x:x+ref_tile_width] = reference_tile\n</code></pre>"},{"location":"encoder/","title":"Documentaci\u00f3 de encoder.py","text":""},{"location":"encoder/#funcions","title":"Funcions","text":""},{"location":"encoder/#encoder.calculate_average_value","title":"<code>calculate_average_value(image)</code>","text":"<p>Calcula el valor mitj\u00e0 d'una imatge en escala de grisos o color.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>Una imatge com un array de numpy.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>El valor mitj\u00e0 de la imatge.</p> Source code in <code>encoder.py</code> <pre><code>def calculate_average_value(image) -&gt; float:\n    \"\"\"\n    Calcula el valor mitj\u00e0 d'una imatge en escala de grisos o color.\n\n    Args:\n        image (ndarray): Una imatge com un array de numpy.\n\n    Returns:\n        float: El valor mitj\u00e0 de la imatge.\n    \"\"\"\n    # Convertir la imagen a un array de numpy\n    img_array = np.array(image)\n\n    # Si la imagen es en color (tres canales)\n    if len(img_array.shape) == 3:\n        # Calcular el valor medio para cada canal y luego el promedio de esos valores\n        mean_value = img_array.mean(axis=(0, 1))\n        return mean_value\n    else:\n        # Calcular el valor medio directamente para una imagen en escala de grises\n        mean_value = img_array.mean()\n        return mean_value\n</code></pre>"},{"location":"encoder/#encoder.calculate_correlation","title":"<code>calculate_correlation(current_tile, reference_tile, seekrange)</code>","text":"<p>Calcula la correlaci\u00f3 entre dues teselles d'imatges consecutives amb un despla\u00e7ament m\u00e0xim especificat. Algoritme de correspondencia de tesela.</p> <p>Parameters:</p> Name Type Description Default <code>current_tile</code> <code>ndarray</code> <p>Tesela de la imatge actual.</p> required <code>reference_tile</code> <code>ndarray</code> <p>Tesela de la imatge de refer\u00e8ncia.</p> required <code>seekrange</code> <code>int</code> <p>Despla\u00e7ament m\u00e0xim en la cerca de teselles coincidents.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>tuple</code> <p>Valor de correlaci\u00f3 m\u00e0xima entre les dues teselles considerant el despla\u00e7ament.</p> <code>tuple</code> <code>tuple</code> <p>Posici\u00f3 de despla\u00e7ament de la tesela actual (dx, dy).</p> Source code in <code>encoder.py</code> <pre><code>def calculate_correlation(current_tile, reference_tile, seekrange) -&gt; tuple:\n    \"\"\"\n    Calcula la correlaci\u00f3 entre dues teselles d'imatges consecutives amb un despla\u00e7ament m\u00e0xim especificat. Algoritme de correspondencia de tesela.\n\n    Args:\n        current_tile (ndarray): Tesela de la imatge actual.\n        reference_tile (ndarray): Tesela de la imatge de refer\u00e8ncia.\n        seekrange (int): Despla\u00e7ament m\u00e0xim en la cerca de teselles coincidents.\n\n    Returns:\n        float: Valor de correlaci\u00f3 m\u00e0xima entre les dues teselles considerant el despla\u00e7ament.\n        tuple: Posici\u00f3 de despla\u00e7ament de la tesela actual (dx, dy).\n    \"\"\"\n    # Convertir las teselas a tipo de dato flotante\n    current_tile = current_tile.astype(float)\n    reference_tile = reference_tile.astype(float)\n\n    max_correlation = -1  # Inicializar con un valor m\u00ednimo de correlaci\u00f3n\n    max_dx = 0  # Inicializar el desplazamiento horizontal m\u00e1ximo\n    max_dy = 0  # Inicializar el desplazamiento vertical m\u00e1ximo\n\n    # Recorrer todos los desplazamientos posibles dentro del rango especificado\n    for dy in range(-seekrange, seekrange + 1):\n        for dx in range(-seekrange, seekrange + 1):\n            # Desplazar la tesela actual\n            shifted_current_tile = np.roll(current_tile, shift=(dy, dx), axis=(0, 1))\n\n            # Calcular la media de cada tesela\n            mean_current = np.mean(shifted_current_tile)\n            mean_reference = np.mean(reference_tile)\n\n            # Calcular las diferencias respecto a la media para cada tesela\n            diff_current = shifted_current_tile - mean_current\n            diff_reference = reference_tile - mean_reference\n\n            # Calcular la correlaci\u00f3n entre las dos teselas\n            numerator = np.sum(diff_current * diff_reference)\n            denominator = np.sqrt(np.sum(diff_current ** 2) * np.sum(diff_reference ** 2))\n\n            if denominator != 0 and not np.isnan(denominator):\n                correlation = numerator / denominator\n                if correlation &gt; max_correlation:\n                    max_correlation = correlation\n                    max_dx = dx\n                    max_dy = dy      \n\n    return max_correlation, (max_dx, max_dy)\n</code></pre>"},{"location":"encoder/#encoder.calculate_psnr","title":"<code>calculate_psnr(original_images, compressed_images)</code>","text":"<p>Calcula el PSNR (Peak Signal-to-Noise Ratio) entre imatges originals i comprimides.</p> <p>Parameters:</p> Name Type Description Default <code>original_images</code> <code>dict</code> <p>Diccionari d'imatges originals.</p> required <code>compressed_images</code> <code>dict</code> <p>Diccionari d'imatges comprimides.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>El valor mitj\u00e0 de PSNR entre totes les imatges, o None si no es va poder calcular.</p> Source code in <code>encoder.py</code> <pre><code>def calculate_psnr(original_images, compressed_images) -&gt; float:\n    \"\"\"\n    Calcula el PSNR (Peak Signal-to-Noise Ratio) entre imatges originals i comprimides.\n\n    Args:\n        original_images (dict): Diccionari d'imatges originals.\n        compressed_images (dict): Diccionari d'imatges comprimides.\n\n    Returns:\n        float: El valor mitj\u00e0 de PSNR entre totes les imatges, o None si no es va poder calcular.\n    \"\"\"\n    psnr_values = []\n    for title, original_image in original_images.items():\n        compressed_image = compressed_images[title]\n\n        # Verificar si las im\u00e1genes tienen el mismo tama\u00f1o\n        if original_image.shape != compressed_image.shape:\n            print(f\"Les dimensions de les imatges {title} s\u00f3n diferents.\")\n            continue\n\n        # Calcular PSNR\n        mse = np.mean((original_image - compressed_image) ** 2)\n        if mse != 0:\n            psnr = 10 * np.log10((255 ** 2) / mse)\n            psnr_values.append(psnr)\n\n    # Calcular PSNR promedio\n    if psnr_values:\n        avg_psnr = np.mean(psnr_values)\n        return avg_psnr\n    else:\n        return None\n</code></pre>"},{"location":"encoder/#encoder.main","title":"<code>main(images, ntiles, seekrange, gop, quality, metadata)</code>","text":"<p>Processa les imatges per a la codificaci\u00f3, dividint-les en grups segons el GOP (Group of Pictures)  i aplicant els par\u00e0metres especificats per a la codificaci\u00f3.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>dict</code> <p>Diccionari amb les imatges.</p> required <code>ntiles</code> <code>tuple</code> <p>Nombre de teselles en els eixos vertical i horitzontal.</p> required <code>seekrange</code> <code>int</code> <p>Despla\u00e7ament m\u00e0xim en la cerca de teselles coincidents.</p> required <code>gop</code> <code>int</code> <p>Mida del GOP.</p> required <code>quality</code> <code>float</code> <p>Factor de qualitat per determinar la coincid\u00e8ncia de teselles.</p> required <code>metadata</code> <code>dict</code> <p>Diccionari per emmagatzemar la informaci\u00f3 dels fotogrames i els par\u00e0metres de codificaci\u00f3.</p> required Source code in <code>encoder.py</code> <pre><code>def main(images, ntiles, seekrange, gop, quality, metadata):\n    \"\"\"\n    Processa les imatges per a la codificaci\u00f3, dividint-les en grups segons el GOP (Group of Pictures) \n    i aplicant els par\u00e0metres especificats per a la codificaci\u00f3.\n\n    Args:\n        images (dict): Diccionari amb les imatges.\n        ntiles (tuple): Nombre de teselles en els eixos vertical i horitzontal.\n        seekrange (int): Despla\u00e7ament m\u00e0xim en la cerca de teselles coincidents.\n        gop (int): Mida del GOP.\n        quality (float): Factor de qualitat per determinar la coincid\u00e8ncia de teselles.\n        metadata (dict): Diccionari per emmagatzemar la informaci\u00f3 dels fotogrames i els par\u00e0metres de codificaci\u00f3.\n    \"\"\"\n    # Dividir las im\u00e1genes en grupos seg\u00fan el GOP\n    image_groups = split_images_into_groups(images, gop)\n    num_processors = multiprocessing.cpu_count()\n    thread_limit = num_processors\n    #thread_limit = num_processors // 2\n\n    with tqdm(total=len(image_groups), desc=\"Processant grups d'imatges\") as pbar:\n        with ThreadPoolExecutor(max_workers=thread_limit) as executor:\n            futures = []\n            for index, image_group in enumerate(image_groups):\n                future = executor.submit(process_image_group, image_group, ntiles, seekrange, quality, images, metadata, index)\n                futures.append(future)\n\n            for future in as_completed(futures):\n                future.result()\n                pbar.update(1)\n    pbar.close()\n    # Ordenar los metadatos por nombre de archivo\n    metadata[\"frames\"].sort(key=lambda x: x[\"file_name\"])\n</code></pre>"},{"location":"encoder/#encoder.mark_tile_for_removal","title":"<code>mark_tile_for_removal(tiles_to_remove, tile_index, current_tile)</code>","text":"<p>Marca una tesela per ser eliminada emmagatzemant el seu \u00edndex en un diccionari.</p> <p>Parameters:</p> Name Type Description Default <code>tiles_to_remove</code> <code>dict</code> <p>Diccionari que emmagatzema els \u00edndexs de les teselles a eliminar, indexats per la seva posici\u00f3.</p> required <code>tile_index</code> <code>tuple</code> <p>L'\u00edndex de la tesela dins de la seva imatge.</p> required <code>current_tile</code> <code>ndarray</code> <p>La tesela actual.</p> required Source code in <code>encoder.py</code> <pre><code>def mark_tile_for_removal(tiles_to_remove, tile_index, current_tile):\n    \"\"\"\n    Marca una tesela per ser eliminada emmagatzemant el seu \u00edndex en un diccionari.\n\n    Args:\n        tiles_to_remove (dict): Diccionari que emmagatzema els \u00edndexs de les teselles a eliminar, indexats per la seva posici\u00f3.\n        tile_index (tuple): L'\u00edndex de la tesela dins de la seva imatge.\n        current_tile (ndarray): La tesela actual.\n    \"\"\"\n    if tile_index not in tiles_to_remove:\n        tiles_to_remove[tile_index] = current_tile\n</code></pre>"},{"location":"encoder/#encoder.process_image_group","title":"<code>process_image_group(image_group, ntiles, seekrange, quality, images, metadata, group_index)</code>","text":"<p>Processa un grup d'imatges, dividint-les en teselles i aplicant l'algorisme de correlaci\u00f3 per a la codificaci\u00f3.</p> <p>Parameters:</p> Name Type Description Default <code>image_group</code> <code>dict</code> <p>Grup d'imatges a processar.</p> required <code>ntiles</code> <code>tuple</code> <p>Nombre de teselles en els eixos vertical i horitzontal.</p> required <code>seekrange</code> <code>int</code> <p>Despla\u00e7ament m\u00e0xim en la cerca de teselles coincidents.</p> required <code>quality</code> <code>float</code> <p>Factor de qualitat per determinar la coincid\u00e8ncia de teselles.</p> required <code>images</code> <code>dict</code> <p>Diccionari amb les imatges.</p> required <code>metadata</code> <code>dict</code> <p>Diccionari per emmagatzemar la informaci\u00f3 dels fotogrames i els par\u00e0metres de codificaci\u00f3.</p> required <code>group_index</code> <code>int</code> <p>\u00cdndex del grup d'imatges.</p> required Source code in <code>encoder.py</code> <pre><code>def process_image_group(image_group, ntiles, seekrange, quality, images, metadata, group_index):\n    \"\"\"\n    Processa un grup d'imatges, dividint-les en teselles i aplicant l'algorisme de correlaci\u00f3 per a la codificaci\u00f3.\n\n    Args:\n        image_group (dict): Grup d'imatges a processar.\n        ntiles (tuple): Nombre de teselles en els eixos vertical i horitzontal.\n        seekrange (int): Despla\u00e7ament m\u00e0xim en la cerca de teselles coincidents.\n        quality (float): Factor de qualitat per determinar la coincid\u00e8ncia de teselles.\n        images (dict): Diccionari amb les imatges.\n        metadata (dict): Diccionari per emmagatzemar la informaci\u00f3 dels fotogrames i els par\u00e0metres de codificaci\u00f3.\n        group_index (int): \u00cdndex del grup d'imatges.\n    \"\"\"\n    reference_image = None\n    tiles_to_remove = {}\n\n    for file_name, image in tqdm(image_group.items(), desc=f\"Processant grup {group_index}\", leave=False):\n        height, width = image.shape[:2]\n        tile_height = height // ntiles[1]\n        tile_width = width // ntiles[0]\n        tiles = subdivide_image_into_tiles(image, tile_height, tile_width, ntiles)\n\n        if reference_image is not None:\n            frame_info = {\n                \"file_name\": file_name,\n                \"reference_frame\": False,\n                \"tiles\": []\n            }\n\n            for tile_index, current_tile in tqdm(tiles.items(), desc=f\"Processant tessel\u00b7les del grup {group_index}\", leave=False):\n                for previous_index, previous_tile in reference_tiles.items():\n                    # Aplicar el algoritmo de correlaci\u00f3n\n                    correlation_score, (dx, dy) = calculate_correlation(current_tile, previous_tile, seekrange)\n                    # Comparar el resultado con el umbral de calidad\n                    if correlation_score &gt;= quality:\n                        # Marcar la tesela para ser eliminada\n                        mark_tile_for_removal(tiles_to_remove, tile_index, current_tile)\n                        # Guardar la informaci\u00f3n de la tesela en el diccionario de metadatos\n                        x = tile_index[1] * tile_width + dx\n                        y = tile_index[0] * tile_height + dy\n                        if x &lt; 0:\n                            x = 0\n                        if y &lt; 0:\n                            y = 0\n                        frame_info[\"tiles\"].append({\"tb_id\": previous_index, \"td_position\": (x, y)})\n\n            if tiles_to_remove:\n                # Calcular el valor medio de la imagen\n                average_value = calculate_average_value(image)\n                # Procesar las teselas marcadas para eliminaci\u00f3n\n                tmp_tiles = tiles.copy()\n                replace_tile_with_average(tmp_tiles, tiles_to_remove, average_value)\n                tiles_to_remove.clear()\n                # Reconstruir la imagen desde las teselas modificadas\n                reconstructed_image = reconstruct_image_from_tiles(list(tmp_tiles.values()), ntiles, image.shape, tile_height, tile_width)\n                # Actualizar la imagen original en el diccionario con la imagen reconstruida\n                images[file_name] = reconstructed_image\n        else:\n            reference_image = image\n            reference_tiles = tiles\n            frame_info = {\n                \"file_name\": file_name,\n                \"reference_frame\": True\n            }\n\n        metadata[\"frames\"].append(frame_info)\n</code></pre>"},{"location":"encoder/#encoder.reconstruct_image_from_tiles","title":"<code>reconstruct_image_from_tiles(tiles, n_tiles, original_shape, tile_height, tile_width)</code>","text":"<p>Reconstrueix la imatge original a partir de les teselles.</p> <p>Parameters:</p> Name Type Description Default <code>tiles</code> <code>dict</code> <p>Diccionari de teselles.</p> required <code>n_tiles</code> <code>tuple</code> <p>Nombre de teselles en els eixos vertical i horitzontal (n_tiles_y, n_tiles_x).</p> required <code>original_shape</code> <code>tuple</code> <p>La forma original de la imatge (altura, amplada, canals).</p> required <code>tile_height</code> <code>int</code> <p>Al\u00e7ada de cada tesela.</p> required <code>tile_width</code> <code>int</code> <p>Amplada de cada tesela.</p> required <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>La imatge reconstru\u00efda com una matriu de numpy.</p> Source code in <code>encoder.py</code> <pre><code>def reconstruct_image_from_tiles(tiles, n_tiles, original_shape, tile_height, tile_width) -&gt; ndarray:\n    \"\"\"\n    Reconstrueix la imatge original a partir de les teselles.\n\n    Args:\n        tiles (dict): Diccionari de teselles.\n        n_tiles (tuple): Nombre de teselles en els eixos vertical i horitzontal (n_tiles_y, n_tiles_x).\n        original_shape (tuple): La forma original de la imatge (altura, amplada, canals).\n        tile_height (int): Al\u00e7ada de cada tesela.\n        tile_width (int): Amplada de cada tesela.\n\n    Returns:\n        ndarray: La imatge reconstru\u00efda com una matriu de numpy.\n    \"\"\"\n    reconstructed_image = np.zeros(original_shape, dtype=tiles[0].dtype)\n\n    count = 0\n    for i in range(n_tiles[0]):\n        for j in range(n_tiles[1]):\n            reconstructed_image[i*tile_height:(i+1)*tile_height, j*tile_width:(j+1)*tile_width] = tiles[count]\n            count += 1\n\n    return reconstructed_image\n</code></pre>"},{"location":"encoder/#encoder.replace_tile_with_average","title":"<code>replace_tile_with_average(tiles, tiles_to_remove, average_value)</code>","text":"<p>Reempla\u00e7a les teselles marcades per eliminaci\u00f3 pel seu valor mitj\u00e0.</p> <p>Parameters:</p> Name Type Description Default <code>tiles</code> <code>dict</code> <p>Diccionari de teselles.</p> required <code>tiles_to_remove</code> <code>dict</code> <p>Diccionari que emmagatzema els \u00edndexs de les teselles a eliminar.</p> required <code>average_value</code> <code>float</code> <p>El valor mitj\u00e0 que s'utilitzar\u00e0 per reempla\u00e7ar les teselles marcades.</p> required Source code in <code>encoder.py</code> <pre><code>def replace_tile_with_average(tiles, tiles_to_remove, average_value):\n    \"\"\"\n    Reempla\u00e7a les teselles marcades per eliminaci\u00f3 pel seu valor mitj\u00e0.\n\n    Args:\n        tiles (dict): Diccionari de teselles.\n        tiles_to_remove (dict): Diccionari que emmagatzema els \u00edndexs de les teselles a eliminar.\n        average_value (float): El valor mitj\u00e0 que s'utilitzar\u00e0 per reempla\u00e7ar les teselles marcades.\n    \"\"\"\n    for tile_index in tiles_to_remove.keys():\n        if tile_index in tiles:\n            tiles[tile_index] = np.full_like(tiles[tile_index], average_value)\n</code></pre>"},{"location":"encoder/#encoder.split_images_into_groups","title":"<code>split_images_into_groups(images, gop)</code>","text":"<p>Divideix la llista d'imatges en conjunts consecutius segons el GOP (Grup de Fotogrames).</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>dict</code> <p>Diccionari d'imatges.</p> required <code>gop</code> <code>int</code> <p>Mida del GOP.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>Llista de diccionaris, on cada diccionari cont\u00e9 imatges consecutives de mida gop.</p> Source code in <code>encoder.py</code> <pre><code>def split_images_into_groups(images, gop) -&gt; list:\n    \"\"\"\n    Divideix la llista d'imatges en conjunts consecutius segons el GOP (Grup de Fotogrames).\n\n    Args:\n        images (dict): Diccionari d'imatges.\n        gop (int): Mida del GOP.\n\n    Returns:\n        list: Llista de diccionaris, on cada diccionari cont\u00e9 imatges consecutives de mida gop.\n    \"\"\"\n    image_groups = []\n    for i in range(0, len(images), gop):\n        # Obtener el conjunto de claves (\u00edndices) de las im\u00e1genes consecutivas de tama\u00f1o gop\n        group_keys = list(images.keys())[i:i+gop]\n\n        # Crear un diccionario para almacenar las im\u00e1genes en este grupo\n        group_images = {key: images[key] for key in group_keys}\n\n        # Agregar este diccionario al grupo de im\u00e1genes\n        image_groups.append(group_images)\n    return image_groups\n</code></pre>"},{"location":"encoder/#encoder.subdivide_image_into_tiles","title":"<code>subdivide_image_into_tiles(image, tile_height, tile_width, n_tiles)</code>","text":"<p>Subdivideix una imatge en el nombre especificat de teselles.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>Matriu de dades de la imatge.</p> required <code>tile_height</code> <code>int</code> <p>Al\u00e7ada de cada tesela.</p> required <code>tile_width</code> <code>int</code> <p>Amplada de cada tesela.</p> required <code>n_tiles</code> <code>tuple</code> <p>Nombre de teselas en els eixos vertical i horitzontal.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Diccionari on les claus s\u00f3n els \u00edndexos de les teselles i els valors s\u00f3n les subimatges (teselles).</p> Source code in <code>encoder.py</code> <pre><code>def subdivide_image_into_tiles(image, tile_height, tile_width, n_tiles) -&gt; dict:\n    \"\"\"\n    Subdivideix una imatge en el nombre especificat de teselles.\n\n    Args:\n        image (ndarray): Matriu de dades de la imatge.\n        tile_height (int): Al\u00e7ada de cada tesela.\n        tile_width (int): Amplada de cada tesela.\n        n_tiles (tuple): Nombre de teselas en els eixos vertical i horitzontal.\n\n    Returns:\n        dict: Diccionari on les claus s\u00f3n els \u00edndexos de les teselles i els valors s\u00f3n les subimatges (teselles).\n    \"\"\"\n    tiles = {}\n    for i in range(n_tiles[0]):\n        for j in range(n_tiles[1]):\n            tile = image[i*tile_height:(i+1)*tile_height, j*tile_width:(j+1)*tile_width]\n            tiles[(i,j)] = tile\n    return tiles\n</code></pre>"},{"location":"filters/","title":"Documentaci\u00f3 de filters.py","text":""},{"location":"filters/#funcions","title":"Funcions","text":""},{"location":"filters/#filters.apply_filter_to_images","title":"<code>apply_filter_to_images(filter_func, images, *args)</code>","text":"<p>Aplica una funci\u00f3 de filtre espec\u00edfica a cada imatge d'un diccionari d'imatges.</p> <p>Parameters:</p> Name Type Description Default <code>filter_func</code> <code>funci\u00f3</code> <p>La funci\u00f3 de filtre a aplicar a les imatges.</p> required <code>images</code> <code>dict</code> <p>Diccionari que cont\u00e9 les imatges a les quals s'aplicar\u00e0 el filtre.</p> required <code>*args</code> <code>int or float or tuple or None</code> <p>Arguments addicionals que es passaran a la funci\u00f3 de filtre.</p> <code>()</code> Source code in <code>filters.py</code> <pre><code>def apply_filter_to_images(filter_func, images, *args:int or float or tuple or None):\n    \"\"\"\n    Aplica una funci\u00f3 de filtre espec\u00edfica a cada imatge d'un diccionari d'imatges.\n\n    Args:\n        filter_func (funci\u00f3): La funci\u00f3 de filtre a aplicar a les imatges.\n        images (dict): Diccionari que cont\u00e9 les imatges a les quals s'aplicar\u00e0 el filtre.\n        *args: Arguments addicionals que es passaran a la funci\u00f3 de filtre.\n    \"\"\"\n    for file_name, image_data in tqdm(images.items(), desc=\"Aplicant filtre\"):\n        images[file_name] = filter_func(image_data, *args)\n</code></pre>"},{"location":"filters/#filters.averaging","title":"<code>averaging(image, kernel_size)</code>","text":"<p>Aplica un filtre de promig a una imatge.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>La imatge d'entrada.</p> required <code>kernel_size</code> <code>int</code> <p>La mida del kernel per al filtre de promig. Si no es proporciona, s'utilitza un valor predeterminat de 3.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: La imatge resultante despr\u00e9s d'aplicar el filtre de promig.</p> Source code in <code>filters.py</code> <pre><code>def averaging(image, kernel_size) -&gt; ndarray:\n    \"\"\"\n    Aplica un filtre de promig a una imatge.\n\n    Args:\n        image (numpy.ndarray): La imatge d'entrada.\n        kernel_size (int): La mida del kernel per al filtre de promig. Si no es proporciona, s'utilitza un valor predeterminat de 3.\n\n    Returns:\n        numpy.ndarray: La imatge resultante despr\u00e9s d'aplicar el filtre de promig.\n    \"\"\"\n    if kernel_size is None:\n        kernel_size = 3\n    kernel = generate_averaging_kernel(kernel_size)\n    channels = cv2.split(image)\n    averaged_channels = [cv2.filter2D(channel, -1, kernel) for channel in channels]\n    averaged_image = cv2.merge(averaged_channels)\n    return averaged_image\n</code></pre>"},{"location":"filters/#filters.binaritzar","title":"<code>binaritzar(image, threshold)</code>","text":"<p>Aplica una binaritzaci\u00f3 a una imatge a partir d'un valor de llindar espec\u00edfic.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>La imatge a binaritzar.</p> required <code>threshold</code> <code>int</code> <p>El valor de llindar per a la binaritzaci\u00f3. Si no es proporciona, s'utilitza el valor predeterminat de 128.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: La imatge bin\u00e0ria resultant despr\u00e9s d'aplicar la binaritzaci\u00f3.</p> Source code in <code>filters.py</code> <pre><code>def binaritzar(image, threshold) -&gt; ndarray:\n    \"\"\"\n    Aplica una binaritzaci\u00f3 a una imatge a partir d'un valor de llindar espec\u00edfic.\n\n    Args:\n        image (numpy.ndarray): La imatge a binaritzar.\n        threshold (int): El valor de llindar per a la binaritzaci\u00f3. Si no es proporciona, s'utilitza el valor predeterminat de 128.\n\n    Returns:\n        numpy.ndarray: La imatge bin\u00e0ria resultant despr\u00e9s d'aplicar la binaritzaci\u00f3.\n    \"\"\"\n    if threshold == None:\n        threshold = 128\n    _, binary_image = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n    return binary_image\n</code></pre>"},{"location":"filters/#filters.blur","title":"<code>blur(image, kernel_size)</code>","text":"<p>Aplica un filtre de desenfocament gaussi\u00e0 a una imatge.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>La imatge d'entrada.</p> required <code>kernel_size</code> <code>int</code> <p>La mida del kernel per al filtre de desenfocament. Si no es proporciona, s'utilitza un valor predeterminat de 3.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: La imatge resultante despr\u00e9s d'aplicar el filtre de desenfocament gaussi\u00e0.</p> Source code in <code>filters.py</code> <pre><code>def blur(image, kernel_size) -&gt; ndarray:\n    \"\"\"\n    Aplica un filtre de desenfocament gaussi\u00e0 a una imatge.\n\n    Args:\n        image (numpy.ndarray): La imatge d'entrada.\n        kernel_size (int): La mida del kernel per al filtre de desenfocament. Si no es proporciona, s'utilitza un valor predeterminat de 3.\n\n    Returns:\n        numpy.ndarray: La imatge resultante despr\u00e9s d'aplicar el filtre de desenfocament gaussi\u00e0.\n    \"\"\"\n    if kernel_size is None:\n        kernel_size = 3\n    kernel = generate_blur_kernel(kernel_size)\n    channels = cv2.split(image)\n    blurred_channels = [cv2.filter2D(channel, -1, kernel) for channel in channels]\n    blurred_image = cv2.merge(blurred_channels)\n    return blurred_image\n</code></pre>"},{"location":"filters/#filters.bordes","title":"<code>bordes(image)</code>","text":"<p>Detecta contorns en una imatge utilitzant l'operador de Sobel.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>La imatge d'entrada.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: La imatge resultant que mostra els contorns detectats.</p> Source code in <code>filters.py</code> <pre><code>def bordes(image) -&gt; ndarray:\n    \"\"\"\n    Detecta contorns en una imatge utilitzant l'operador de Sobel.\n\n    Args:\n        image (numpy.ndarray): La imatge d'entrada.\n\n    Returns:\n        numpy.ndarray: La imatge resultant que mostra els contorns detectats.\n    \"\"\"\n    sobel_kernel_x = np.array([[-1, 0, 1],\n                               [-2, 0, 2],\n                               [-1, 0, 1]], dtype=np.float32)\n    sobel_kernel_y = np.array([[1,  2,  1],\n                               [0,  0,  0],\n                               [-1, -2, -1]], dtype=np.float32)\n    sobelx = cv2.filter2D(image, cv2.CV_64F, sobel_kernel_x)\n    sobely = cv2.filter2D(image, cv2.CV_64F, sobel_kernel_y)\n    edges = cv2.magnitude(sobelx, sobely)\n    edges = np.uint8(edges)\n    return edges\n</code></pre>"},{"location":"filters/#filters.brillo_contraste","title":"<code>brillo_contraste(image, brillo_contraste)</code>","text":"<p>Ajusta el brillo y el contrast per a una imatge.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>La imatge d'entrada.</p> required <code>brillo_contraste</code> <code>tuple</code> <p>Tupla que cont\u00e9 l'ajust de brillantor i contrast. El primer valor de la tupla \u00e9s l'ajust de brillantor, on un valor major que 1 augmentar\u00e0 el brillantor i un valor menor que 1 el disminuir\u00e0. El segon valor de la tupla \u00e9s l'ajust de contrast, on un valor major que 1 augmentar\u00e0 el contrast i un valor menor que 1 el disminuir\u00e0.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: La imatge resultant despr\u00e9s d'aplicar els ajustos de brillantor i contrast.</p> Source code in <code>filters.py</code> <pre><code>def brillo_contraste(image, brillo_contraste) -&gt; ndarray:\n    \"\"\"\n    Ajusta el brillo y el contrast per a una imatge.\n\n    Args:\n        image (numpy.ndarray): La imatge d'entrada.\n        brillo_contraste (tuple): Tupla que cont\u00e9 l'ajust de brillantor i contrast.\n            El primer valor de la tupla \u00e9s l'ajust de brillantor, on un valor major que 1 augmentar\u00e0 el brillantor i un valor menor que 1 el disminuir\u00e0.\n            El segon valor de la tupla \u00e9s l'ajust de contrast, on un valor major que 1 augmentar\u00e0 el contrast i un valor menor que 1 el disminuir\u00e0.\n\n    Returns:\n        numpy.ndarray: La imatge resultant despr\u00e9s d'aplicar els ajustos de brillantor i contrast.\n    \"\"\"\n    return cv2.convertScaleAbs(image, alpha=brillo_contraste[1], beta=brillo_contraste[0])\n</code></pre>"},{"location":"filters/#filters.embossing","title":"<code>embossing(image)</code>","text":"<p>Aplica un filtre de relleu a una imatge.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>La imatge d'entrada.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: La imatge resultant despr\u00e9s d'aplicar el filtre de relleu.</p> Source code in <code>filters.py</code> <pre><code>def embossing(image) -&gt; ndarray:\n    \"\"\"\n    Aplica un filtre de relleu a una imatge.\n\n    Args:\n        image (numpy.ndarray): La imatge d'entrada.\n\n    Returns:\n        numpy.ndarray: La imatge resultant despr\u00e9s d'aplicar el filtre de relleu.\n    \"\"\"\n    kernel = np.array([[-1, -1, 0],\n                       [-1,  0,  1],\n                       [0,   1,  1]], dtype=np.float32)\n    return cv2.filter2D(image, -1, kernel)\n</code></pre>"},{"location":"filters/#filters.generate_averaging_kernel","title":"<code>generate_averaging_kernel(size)</code>","text":"<p>Genera un kernel per al filtre de promig.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>La mida del kernel.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: El kernel generat per al filtre de promig.</p> Source code in <code>filters.py</code> <pre><code>def generate_averaging_kernel(size) -&gt; ndarray:\n    \"\"\"\n    Genera un kernel per al filtre de promig.\n\n    Args:\n        size (int): La mida del kernel.\n\n    Returns:\n        numpy.ndarray: El kernel generat per al filtre de promig.\n    \"\"\"\n    kernel = np.ones((size, size), dtype=np.float32) / (size * size)\n    return kernel\n</code></pre>"},{"location":"filters/#filters.generate_blur_kernel","title":"<code>generate_blur_kernel(size)</code>","text":"<p>Genera un kernel per al filtre de desenfocament gaussi\u00e0.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>La mida del kernel.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: El kernel generat per al filtre de desenfocament gaussi\u00e0.</p> Source code in <code>filters.py</code> <pre><code>def generate_blur_kernel(size) -&gt; ndarray:\n    \"\"\"\n    Genera un kernel per al filtre de desenfocament gaussi\u00e0.\n\n    Args:\n        size (int): La mida del kernel.\n\n    Returns:\n        numpy.ndarray: El kernel generat per al filtre de desenfocament gaussi\u00e0.\n    \"\"\"\n    if size % 2 == 0:\n        raise ValueError(\"El tama\u00f1o del kernel debe ser impar.\")\n    sigma = 0.3 * ((size - 1) * 0.5 - 1) + 0.8\n    kernel = cv2.getGaussianKernel(size, sigma)\n    kernel = np.outer(kernel, kernel)\n    return kernel\n</code></pre>"},{"location":"filters/#filters.main","title":"<code>main(filters_split, images, metadata, click, is_encoded, is_grayscale)</code>","text":"<p>Processa les imatges segons el filtres especificat i els par\u00e0metres proporcionats.</p> <p>Parameters:</p> Name Type Description Default <code>filters_split</code> <code>list</code> <p>Llista de Strings que contenen el nom del filtre i els seus par\u00e0metres, si n'hi ha.</p> required <code>images</code> <code>dict</code> <p>Diccionari que cont\u00e9 les imatges a processar.</p> required <code>metadata</code> <code>dict</code> <p>Metadades del programa.</p> required <code>click</code> <code>m\u00f2dul</code> <p>M\u00f2dul Click per a la interacci\u00f3 amb l'usuari.</p> required <code>is_encoded</code> <code>bool</code> <p>Indica si les imatges han estat codificades pr\u00e8viament.</p> required <code>is_grayscale</code> <code>bool</code> <p>Indica si les imatges s\u00f3n en escala de grisos.</p> required Source code in <code>filters.py</code> <pre><code>def main(filters_split, images, metadata, click, is_encoded, is_grayscale):\n    \"\"\"\n    Processa les imatges segons el filtres especificat i els par\u00e0metres proporcionats.\n\n    Args:\n        filters_split (list): Llista de Strings que contenen el nom del filtre i els seus par\u00e0metres, si n'hi ha.\n        images (dict): Diccionari que cont\u00e9 les imatges a processar.\n        metadata (dict): Metadades del programa.\n        click (m\u00f2dul): M\u00f2dul Click per a la interacci\u00f3 amb l'usuari.\n        is_encoded (bool): Indica si les imatges han estat codificades pr\u00e8viament.\n        is_grayscale (bool): Indica si les imatges s\u00f3n en escala de grisos.\n    \"\"\"\n    filters_applied = []\n    filters_not_compatible = [\"sepia\", \"grey\"]\n\n    if is_encoded: # Si se ha codificado previamente, cogemos la informaci\u00f3n de los filtros aplicados\n        filters_applied = [filter['filter_name'] for filter in metadata['filters']]\n\n    for filter_str in filters_split:\n        if '=' in filter_str:\n            filter_name, filter_value = filter_str.split('=')\n            if ',' in filter_value:\n                filter_value = filter_value.split(',')\n                filter_value = float(filter_value[0]), float(filter_value[1])\n                filter_value = tuple(filter_value)\n            elif filter_value.isdigit():\n                filter_value = int(filter_value)\n        else:\n            filter_name, filter_value = filter_str, None\n\n        if filter_name in filters_applied:\n            click.echo(f'El filtre {filter_name} ja ha estat aplicat anteriorment.')\n            continue\n        if filter_name in filters_not_compatible and any(item in filters_applied for item in filters_not_compatible):\n            click.echo(f'El filtre {filter_name} no \u00e9s compatible amb els filtres aplicats anteriorment.')\n            continue\n        if is_grayscale and filter_name in filters_not_compatible:\n            click.echo(f'El filtre {filter_name} no \u00e9s compatible amb imatges en escala de grisos.')\n            continue\n        filter_func = {\n            'binarization': binaritzar,\n            'brillo': brillo_contraste,\n            'negative': negative,\n            'sepia': sepia,\n            'grey': lambda img: cv2.cvtColor(img, cv2.COLOR_BGR2GRAY),\n            'averaging': averaging,\n            'blur': blur,\n            'edges': bordes,\n            'embossing': embossing,\n            'sharp': sharp,\n        }.get(filter_name)\n\n        if filter_func:\n            # valors per defecte\n            if filter_name == 'averaging':\n                filter_value = 3\n            elif filter_name == 'blur':\n                filter_value = 3\n            elif filter_name == 'binarization':\n                filter_value = 128\n            elif filter_name == 'brillo':\n                filter_value = (50.0, 1.5)\n\n            start_time = time.time()\n            if filter_value:\n                apply_filter_to_images(filter_func, images, filter_value)\n                end_time = time.time()\n                total_time = end_time - start_time\n                click.echo(f'Aplicat filtre {filter_name} amb els par\u00e0metres: {filter_value}. Temps total: {str(round(total_time))} segons.')\n            else:\n                apply_filter_to_images(filter_func, images)\n                end_time = time.time()\n                total_time = end_time - start_time\n                click.echo(f'Aplicat filtre {filter_name}. Temps total: {str(round(total_time))} segons.')\n\n            filters_applied.append(filter_name)\n            metadata[\"filters\"].append({\"filter_name\": filter_name, \"parameters\": filter_value})\n</code></pre>"},{"location":"filters/#filters.negative","title":"<code>negative(image)</code>","text":"<p>Crea una imatge negativa d'una imatge donada.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>La imatge d'entrada.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: La imatge resultant que \u00e9s la negativa de la imatge d'entrada.</p> Source code in <code>filters.py</code> <pre><code>def negative(image) -&gt; ndarray:\n    \"\"\"\n    Crea una imatge negativa d'una imatge donada.\n\n    Args:\n        image (numpy.ndarray): La imatge d'entrada.\n\n    Returns:\n        numpy.ndarray: La imatge resultant que \u00e9s la negativa de la imatge d'entrada.\n    \"\"\"\n    return 255 - image\n</code></pre>"},{"location":"filters/#filters.sepia","title":"<code>sepia(image)</code>","text":"<p>Aplica un efecte s\u00e8pia a una imatge.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>La imatge d'entrada.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: La imatge resultant amb l'efecte s\u00e8pia aplicat.</p> Source code in <code>filters.py</code> <pre><code>def sepia(image) -&gt; ndarray:\n    \"\"\"\n    Aplica un efecte s\u00e8pia a una imatge.\n\n    Args:\n        image (numpy.ndarray): La imatge d'entrada.\n\n    Returns:\n        numpy.ndarray: La imatge resultant amb l'efecte s\u00e8pia aplicat.\n    \"\"\"\n    sepia_filter = np.array([[0.272, 0.534, 0.131],\n                             [0.349, 0.686, 0.168],\n                             [0.393, 0.769, 0.189]])\n    return cv2.transform(image, sepia_filter)\n</code></pre>"},{"location":"filters/#filters.sharp","title":"<code>sharp(image)</code>","text":"<p>Aplica un filtre de millora a una imatge.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>La imatge d'entrada.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: La imatge resultante despr\u00e9s d'aplicar el filtre de millora.</p> Source code in <code>filters.py</code> <pre><code>def sharp(image) -&gt; ndarray:\n    \"\"\"\n    Aplica un filtre de millora a una imatge.\n\n    Args:\n        image (numpy.ndarray): La imatge d'entrada.\n\n    Returns:\n        numpy.ndarray: La imatge resultante despr\u00e9s d'aplicar el filtre de millora.\n    \"\"\"\n    kernel = np.array([[0, -1, 0],\n                       [-1,  5, -1],\n                       [0, -1, 0]], dtype=np.float32)\n    return cv2.filter2D(image, -1, kernel)\n</code></pre>"},{"location":"input/","title":"Documentaci\u00f3 de read_input.py","text":""},{"location":"input/#funcions","title":"Funcions","text":""},{"location":"input/#read_input.open_zip","title":"<code>open_zip(zip_path, images, metadata)</code>","text":"<p>Obre un fitxer ZIP especificat i carrega les imatges v\u00e0lides en un diccionari global.</p> <p>Parameters:</p> Name Type Description Default <code>zip_path</code> <code>str</code> <p>Ruta al fitxer ZIP que s'obrir\u00e0.</p> required <code>images</code> <code>dict</code> <p>Diccionari on s'emmagatzemaran les imatges.</p> required <code>metadata</code> <code>dict</code> <p>Diccionari on s'emmagatzemaran els metadades.</p> required <p>Returns:</p> Type Description <code>tuple[bool, bool]</code> <p>tuple[bool, bool]: Tupla que indica si el fitxer ZIP cont\u00e9 imatges codificades i si cont\u00e9 imatges en escala de grisos.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Si el fitxer ZIP no cont\u00e9 arxius d'imatge v\u00e0lids o si no es pot obrir.</p> Source code in <code>read_input.py</code> <pre><code>def open_zip(zip_path, images, metadata) -&gt; tuple[bool, bool]:\n    \"\"\"\n    Obre un fitxer ZIP especificat i carrega les imatges v\u00e0lides en un diccionari global.\n\n    Args:\n        zip_path (str): Ruta al fitxer ZIP que s'obrir\u00e0.\n        images (dict): Diccionari on s'emmagatzemaran les imatges.\n        metadata (dict): Diccionari on s'emmagatzemaran els metadades.\n\n    Returns:\n        tuple[bool, bool]: Tupla que indica si el fitxer ZIP cont\u00e9 imatges codificades i si cont\u00e9 imatges en escala de grisos.\n\n    Raises:\n        ValueError: Si el fitxer ZIP no cont\u00e9 arxius d'imatge v\u00e0lids o si no es pot obrir.\n    \"\"\"\n    is_encoded = False  # El input es un archivo codificado\u00e7\n    is_grayscale = False  # El input es una imagen en escala de grises\n    with ZipFile(zip_path, 'r') as zip_file:\n        # Obtener la lista de nombres de archivos en el zip ordenada\n        file_list = sorted(zip_file.namelist())\n\n        # Iterar sobre cada archivo en el zip\n        for file_name in file_list:\n            # Verificar si el archivo es un JSON de metadatos del encoder\n            if file_name == 'encoder_metadata.json':\n                # Leer los metadatos del encoder\n                with zip_file.open(file_name) as metadata_file:\n                    metadata.update(json.load(metadata_file))\n                is_encoded = True\n                continue\n            # Verificar si el archivo es una imagen (puedes agregar m\u00e1s extensiones si es necesario)\n            if file_name.endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n                images[file_name] = read_image(file_name, zip_file)\n                # Verificar si la imagen es en escala de grises\n                if len(images[file_name].shape) == 2:\n                    is_grayscale = True\n            else:  # error?\n                print(f'Error: {file_name} no es una imagen v\u00e1lida.')\n    return is_encoded, is_grayscale\n</code></pre>"},{"location":"input/#read_input.read_gif","title":"<code>read_gif(file_name, images)</code>","text":"<p>Llegeix un fitxer GIF, guardant cada fotograma com una entrada separada en el diccionari global.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>Nom del fitxer GIF.</p> required <code>images</code> <code>dict</code> <p>Diccionari on s'emmagatzemaran les imatges.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True si el GIF \u00e9s en escala de grisos, False altrament.</p> Source code in <code>read_input.py</code> <pre><code>def read_gif(file_name, images) -&gt; bool:\n    \"\"\"\n    Llegeix un fitxer GIF, guardant cada fotograma com una entrada separada en el diccionari global.\n\n    Args:\n        file_name (str): Nom del fitxer GIF.\n        images (dict): Diccionari on s'emmagatzemaran les imatges.\n\n    Returns:\n        bool: True si el GIF \u00e9s en escala de grisos, False altrament.\n    \"\"\"\n    # Leer el archivo GIF utilizando imageio\n    gif_images = imageio.mimread(file_name)\n    # Ver si es formato de escala de grises\n    is_grayscale = True if len(gif_images[0].shape) == 2 else False\n    # Iterar sobre cada frame del GIF\n    for i, image_data in enumerate(gif_images):\n        file_name_without_extension = Path(file_name).stem\n        # Agregar cada frame a la lista de im\u00e1genes\n        images[f'{file_name_without_extension}_{i}.gif'] = image_data\n    return is_grayscale\n</code></pre>"},{"location":"input/#read_input.read_image","title":"<code>read_image(file_name, zip_file)</code>","text":"<p>Llegeix una imatge des d'un fitxer dins d'un objecte ZipFile i la retorna com un array de dades.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>Nom del fitxer dins del ZIP.</p> required <code>zip_file</code> <code>ZipFile</code> <p>Objecte ZipFile ja obert des d'on es llegeix el fitxer.</p> required <p>Returns:</p> Name Type Description <code>ndarray</code> <code>ndarray</code> <p>Array de dades de la imatge llegida.</p> <p>Raises:</p> Type Description <code>IOError</code> <p>Si el fitxer d'imatge no es pot llegir.</p> Source code in <code>read_input.py</code> <pre><code>def read_image(file_name, zip_file) -&gt; ndarray:\n    \"\"\"\n    Llegeix una imatge des d'un fitxer dins d'un objecte ZipFile i la retorna com un array de dades.\n\n    Args:\n        file_name (str): Nom del fitxer dins del ZIP.\n        zip_file (ZipFile): Objecte ZipFile ja obert des d'on es llegeix el fitxer.\n\n    Returns:\n        ndarray: Array de dades de la imatge llegida.\n\n    Raises:\n        IOError: Si el fitxer d'imatge no es pot llegir.\n    \"\"\"\n    # Leer la imagen desde el archivo en el zip\n    with zip_file.open(file_name) as image_file:\n        # Utilizar imageio para leer la imagen\n        image_data = imageio.imread(image_file)\n        return image_data\n</code></pre>"},{"location":"input/#read_input.read_video","title":"<code>read_video(file_path, images)</code>","text":"<p>Llegeix un fitxer de v\u00eddeo (AVI, MPEG o MP4) i guarda cada fotograma com una entrada separada en el diccionari global.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Ruta del fitxer de v\u00eddeo.</p> required <code>images</code> <code>dict</code> <p>Diccionari on s'emmagatzemaran les imatges.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True si el v\u00eddeo \u00e9s en escala de grisos, False altrament.</p> Source code in <code>read_input.py</code> <pre><code>def read_video(file_path, images) -&gt; bool:\n    \"\"\"\n    Llegeix un fitxer de v\u00eddeo (AVI, MPEG o MP4) i guarda cada fotograma com una entrada separada en el diccionari global.\n\n    Args:\n        file_path (str): Ruta del fitxer de v\u00eddeo.\n        images (dict): Diccionari on s'emmagatzemaran les imatges.\n\n    Returns:\n        bool: True si el v\u00eddeo \u00e9s en escala de grisos, False altrament.\n    \"\"\"\n    video_capture = cv2.VideoCapture(file_path)\n    if not video_capture.isOpened():\n        raise ValueError(f\"Unable to open video file: {file_path}\")\n\n    is_grayscale = False\n    frame_index = 0\n\n    try:\n        success, frame = video_capture.read()\n\n        # Verify if the video is in grayscale\n        if success and frame is not None:\n            if len(frame.shape) == 2:\n                is_grayscale = True\n\n        while success and frame is not None:\n            # If the video is in grayscale, save the frame without color conversion\n            if is_grayscale:\n                images[f'frame_{frame_index}.jpeg'] = frame\n            else:\n                # If the video is not in grayscale, convert to RGB before saving\n                images[f'frame_{frame_index}.jpeg'] = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            frame_index += 1\n            success, frame = video_capture.read()\n\n    finally:\n        video_capture.release()\n\n    return is_grayscale\n</code></pre>"},{"location":"output/","title":"Documentaci\u00f3 de create_output.py","text":""},{"location":"output/#funcions","title":"Funcions","text":""},{"location":"output/#create_output.create_zip","title":"<code>create_zip(output_path, images, metadata, is_encoded)</code>","text":"<p>Crea un fitxer ZIP a la ruta especificada, guardant les imatges del diccionari global convertides a JPEG.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>str</code> <p>Ruta al fitxer ZIP de sortida.</p> required <code>images</code> <code>dict</code> <p>Diccionari on les claus s\u00f3n noms d'arxiu i els valors s\u00f3n dades d'imatge.</p> required <code>metadata</code> <code>dict</code> <p>Metadades associades a les imatges.</p> required <code>is_encoded</code> <code>bool</code> <p>Indica si els noms dels arxius en els metadades ja estan codificats.</p> required Source code in <code>create_output.py</code> <pre><code>def create_zip(output_path, images, metadata, is_encoded):\n    \"\"\"\n    Crea un fitxer ZIP a la ruta especificada, guardant les imatges del diccionari global convertides a JPEG.\n\n    Args:\n        output_path (str): Ruta al fitxer ZIP de sortida.\n        images (dict): Diccionari on les claus s\u00f3n noms d'arxiu i els valors s\u00f3n dades d'imatge.\n        metadata (dict): Metadades associades a les imatges.\n        is_encoded (bool): Indica si els noms dels arxius en els metadades ja estan codificats.\n    \"\"\"\n    with ZipFile(output_path, 'w') as zip_file:\n        for file_name, image_data in images.items():\n            # Convertir la imagen a formato JPEG\n            jpeg_image = image_to_jpeg(image_data)\n            # Obtener el nombre del archivo sin la extensi\u00f3n\n            file_name_without_extension = Path(file_name).stem\n            # Guardar la imagen en el zip\n            zip_file.writestr(f'{file_name_without_extension}.jpeg', jpeg_image)\n\n        if not is_encoded:\n            # Actualizar los nombres de archivo en los metadatos (.jpeg)\n            updated_metadata = update_metadata_file_names(metadata)\n            # Convertir los metadatos del encoder a formato JSON\n            metadata_json = json.dumps(updated_metadata, indent=4)\n            # Guardar el JSON de los metadatos en el zip\n            zip_file.writestr('encoder_metadata.json', metadata_json)\n</code></pre>"},{"location":"output/#create_output.image_to_jpeg","title":"<code>image_to_jpeg(image_data)</code>","text":"<p>Converteix dades d'imatge en format d'array a format JPEG.</p> <p>Parameters:</p> Name Type Description Default <code>image_data</code> <code>ndarray</code> <p>Dades de la imatge a convertir.</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>Dades de la imatge en format JPEG.</p> Source code in <code>create_output.py</code> <pre><code>def image_to_jpeg(image_data) -&gt; bytes:\n    \"\"\"\n    Converteix dades d'imatge en format d'array a format JPEG.\n\n    Args:\n        image_data (ndarray): Dades de la imatge a convertir.\n\n    Returns:\n        bytes: Dades de la imatge en format JPEG.\n    \"\"\"\n    # Convertir la matriz de la imagen a un objeto BytesIO\n    with io.BytesIO() as output_bytes:\n        # Convertir la matriz de imagen a objeto de imagen PIL\n        image_pil = Image.fromarray(image_data)\n        # Verificar si la imagen tiene un canal alfa (RGBA)\n        if image_pil.mode == 'RGBA':\n            # Si tiene un canal alfa, convertirla a RGB\n            image_pil = image_pil.convert('RGB')\n        # Guardar la imagen PIL en formato JPEG en BytesIO\n        image_pil.save(output_bytes, format='JPEG')\n        # Obtener los bytes de la imagen JPEG\n        jpeg_bytes = output_bytes.getvalue()\n    return jpeg_bytes\n</code></pre>"},{"location":"output/#create_output.update_metadata_file_names","title":"<code>update_metadata_file_names(metadata)</code>","text":"<p>Actualitza els noms dels fitxers als metadades per reflectir l'extensi\u00f3 .jpeg.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>dict</code> <p>Metadades de l'encoder.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Metadades actualitzades amb els noms de fitxer modificats.</p> Source code in <code>create_output.py</code> <pre><code>def update_metadata_file_names(metadata) -&gt; dict:\n    \"\"\"\n    Actualitza els noms dels fitxers als metadades per reflectir l'extensi\u00f3 .jpeg.\n\n    Args:\n        metadata (dict): Metadades de l'encoder.\n\n    Returns:\n        dict: Metadades actualitzades amb els noms de fitxer modificats.\n    \"\"\"\n    for frame in metadata['frames']:    \n        file_name_without_extension = Path(frame['file_name']).stem\n        frame['file_name'] = f'{file_name_without_extension}.jpeg'\n    return metadata\n</code></pre>"},{"location":"reproduce/","title":"Documentaci\u00f3 de reproduce_video.py","text":""},{"location":"reproduce/#funcions","title":"Funcions","text":""},{"location":"reproduce/#reproduce_video.play_video","title":"<code>play_video(fps, images, pbar)</code>","text":"<p>Reprodueix les imatges emmagatzemades en el diccionari global com a v\u00eddeo, en una finestra de OpenCV.</p> <p>Parameters:</p> Name Type Description Default <code>fps</code> <code>int</code> <p>Fotogrames per segon als quals es reproduir\u00e0 el v\u00eddeo.</p> required <code>images</code> <code>dict</code> <p>Diccionari que cont\u00e9 les imatges del v\u00eddeo.</p> required <code>pbar</code> <code>tqdm</code> <p>Barra de progr\u00e9s per mostrar el progr\u00e9s de la reproducci\u00f3.</p> required Source code in <code>reproduce_video.py</code> <pre><code>def play_video(fps, images, pbar):\n    \"\"\"\n    Reprodueix les imatges emmagatzemades en el diccionari global com a v\u00eddeo, en una finestra de OpenCV.\n\n    Args:\n        fps (int): Fotogrames per segon als quals es reproduir\u00e0 el v\u00eddeo.\n        images (dict): Diccionari que cont\u00e9 les imatges del v\u00eddeo.\n        pbar (tqdm): Barra de progr\u00e9s per mostrar el progr\u00e9s de la reproducci\u00f3.\n    \"\"\"\n    global stop_video\n    window_name = 'Video'\n    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n    #cv2.resizeWindow(window_name, 800, 600)\n\n    while not stop_video:\n        for file_name, image_data in images.items():\n            image_cv2_rgb = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)  # Convertir de BGR a RGB\n            cv2.imshow(window_name, image_cv2_rgb)\n            key = cv2.waitKey(int(1000 / fps))  # Convertir fps a milisegundos\n            if key == ord('q'):\n                stop_video = True\n                break\n            pbar.update() \n        pbar.reset()\n    pbar.close()\n    cv2.destroyWindow(window_name)\n</code></pre>"},{"location":"reproduce/#reproduce_video.show_video","title":"<code>show_video(fps, images)</code>","text":"<p>Inicia un fil per reproduir les imatges emmagatzemades com a v\u00eddeo a una velocitat de fps especificada.</p> <p>Parameters:</p> Name Type Description Default <code>fps</code> <code>int</code> <p>Fotogrames per segon als quals es reproduir\u00e0 el v\u00eddeo.</p> required <code>images</code> <code>dict</code> <p>Diccionari que cont\u00e9 les imatges del v\u00eddeo.</p> required Source code in <code>reproduce_video.py</code> <pre><code>def show_video(fps, images):\n    \"\"\"\n    Inicia un fil per reproduir les imatges emmagatzemades com a v\u00eddeo a una velocitat de fps especificada.\n\n    Args:\n        fps (int): Fotogrames per segon als quals es reproduir\u00e0 el v\u00eddeo.\n        images (dict): Diccionari que cont\u00e9 les imatges del v\u00eddeo.\n    \"\"\"\n    pbar = tqdm(total=len(images), desc=\"Reproduciendo video\", unit=\"frames\")\n    thread = Thread(target=play_video, args=(fps, images, pbar))\n    thread.start()\n</code></pre>"}]}